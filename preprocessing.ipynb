{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd07af3995830050bd8f35793b7fb50af8649be5a790127b2059bc5cc64581c1227",
   "display_name": "Python 3.9.2 64-bit ('mne': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Data information\n",
    "\n",
    "Dataset has the following attributes:\n",
    "\n",
    "- type: Event type\n",
    "- duration:  Duration of the event, if it is a fixation, then it is the fixation duration\n",
    "- sac_amplitude: Amplitude of the eye saccades\n",
    "- sac_endpos_x: `x coordinate` of saccades end position \n",
    "- sac_endpos_y: `y coordinate` of saccades end position\n",
    "- sac_startpos_x: `x coordinate` of saccades start position\n",
    "- sac_startpos_y: `y coordinate` of saccades start position\n",
    "- sac_vmax: Maximal velocity of saccade\n",
    "- fix_avgpos_x: Average `x coordinate` position \n",
    "- fix_avgpos_y: Average `y coordinate` position\n",
    "- fix_avgpupilsize: Average pupil size of the eye\n",
    "- overlapping: Whether there are two bounding boxes that are overlapping (e.g. a face, being partially occluded by another head)\n",
    "- fix_samebox: Whether the current fixation is within the same bounding box (e.g. same face) as the previous one.\n",
    "- id: Subject ID\n",
    "- picID: Picture ID\n",
    "- trialnum: Trial Number\n",
    "- fix_type: Type of the fixation.\n",
    "- onset: Event onset time.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task Summary\n",
    "- Analyse dataset and find relation between variables if any"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('sub-45/eeg/sub-45_task-WLFO_events.tsv', sep='\\t')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "we observe that: \n",
    "- 'type' and 'fix_type' are categorial values.\n",
    "- duration, sac_amplitude, sac_endpos_x, sac_endpos_y, sac_startpos_x, sac_startpos_y, sac_vmax, fix_avgpos_x, fix_avgpos_y, fix_avgpupilsize, overlapping, fix_samebox, id, picID, trailnum, onset are numerical attributes\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Understanding categorical variables "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fix_type'].unique()"
   ]
  },
  {
   "source": [
    "### Types:\n",
    "- NonetoNone:Background to Background\n",
    "- NonetoHF - HFtoNone: Background to Human Face - Human Face to Backgound\n",
    "- HFtoHF: Human Face to Human Face\n",
    "- NonetoOS - OStoNone: Background to Outside the image - Outside to background\n",
    "- NonetoHH - HHToNone: Backgound to human head, in difference to human face\n",
    "- OLtoNone: Overlapping bounding box, no unique attribution possible\n",
    "- HFtoNH: Human Face to non human head (e.g. cardboard, or mannequin)\n",
    "- NHtoNone: Non human head (e.g. cardboard, or mannequin) to Backgound\n",
    "- OStoOS: Outside stimulus to outside stimulus\n",
    "- NHtoNH: Non human head (e.g. cardboard, or mannequin) to Non human head (e.g. cardboard, or mannequin)\n",
    "- OLtoHF: Overlapping bounding box to Human Face?\n",
    "- HFtoHH: Human Face to Human Head?\n",
    "- HHtoHH: Human Head to Human Head\n",
    "- NonetoOL: Backgound to Overlapping bounding box\n",
    "- OstoHF - OStoNH: Self decoded\n",
    "- OStoHH - HFtoOS: Self decoded"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "source": [
    "### Triggers\n",
    "- 213, 214, 215 : Recalibration settings for eye tracker\n",
    "- 180: End of stimulus  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`Null Values` in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "# Insights on distribution \n",
    "Plotting individual attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from wordcloud import wordcloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "Define Plotting functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_dis(text):\n",
    "  f= plt.figure(figsize=(21,5))\n",
    "  \n",
    "  ax=f.add_subplot(131)\n",
    "  sns.distplot(df[text],color='b',ax=ax)\n",
    "  ax.set_title('Distribution of {}'.format(text))\n",
    "\n",
    "  ax=f.add_subplot(132)\n",
    "  sns.distplot(df[(df.fix_type == 'NonetoNone')][text], color='g',ax=ax)\n",
    "  ax.set_title('Distribution of {} for Background-Background'.format(text))\n",
    "  \n",
    "  ax=f.add_subplot(133)\n",
    "  sns.distplot(df[(df.fix_type == 'NonetoHF') & (df.fix_type == 'HFtoNone')][text],color='c',ax=ax)\n",
    "  ax.set_title('Distribution of {} for Background-HumanFace and vice-versa'.format(text))\n",
    "\n",
    "  f1= plt.figure(figsize=(13,5))\n",
    "  \n",
    "  ax=f1.add_subplot(121)\n",
    "  sns.distplot(df[(df.fix_type == 'HFtoHF')][text],color='g',ax=ax)\n",
    "  ax.set_title('Distribution of {} for HumanFace-HumanFace'.format(text))\n",
    "\n",
    "  ax=f1.add_subplot(122)\n",
    "  sns.distplot(df[(df.fix_type == 'HFtoOS') & (df.fix_type == 'OStoHF')][text],color='g',ax=ax)\n",
    "  ax.set_title('Distribution of {} for HumanFace-Outside and vice versa'.format(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_box(text):\n",
    "  fig, axes = plt.subplots(figsize=(25, 15))\n",
    "  fig.suptitle('Box plot of {}'.format(text))\n",
    "  sns.boxplot(ax=axes, data=df, y=text, x='fix_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_scat(parameter1, parameter2,var1,var2):\n",
    "  \n",
    "  f= plt.figure(figsize=(25,5))\n",
    "  ax=f.add_subplot(121)\n",
    "  sns.scatterplot(x=parameter1,y=parameter2,hue=var1,data=df,ax=ax)\n",
    "  ax.set_title('Relationship between {} and {} in function of {}'.format(parameter1,parameter2,var1))\n",
    "  \n",
    "  ax=f.add_subplot(122)\n",
    "  sns.scatterplot(x=parameter1, y=parameter2,hue=var2,data=df,ax=ax)\n",
    "  ax.set_title('Relationship between {} and {} in function of {}'.format(parameter1,parameter2,var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_dis('sac_amplitude')"
   ]
  },
  {
   "source": [
    "It appears that we mostly have right skewed distribution and, \n",
    "- People are are spending more time in background to background fixation which seems strange! Normally we have tendency to look foreground objects in the image.\n",
    "- People are are spending more time doing human to human fixation which seems okay. This supports the hypothesis that we have tendency to look foreground objects in the image.\n",
    "\n",
    "Futhermore, we can see that most test subjects are either looking/exploring the image background and then the image foreground -- and we don't have a significant effect at the boundary i.e. between image foreground and background. It is like we are segmenting the image and looking at individual pieces."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_dis('onset')"
   ]
  },
  {
   "source": [
    "It looks like the onset distribution is somewhat periodic with peaks at 500, 1500, 2500. \n",
    "\n",
    "Also, at the peak or at the middle of a period, the subjects have higher tendency of looking at the background of the image. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_box('sac_amplitude')"
   ]
  },
  {
   "source": [
    "### Plotting scatter plots for eye fixations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_scat('sac_startpos_x', 'sac_startpos_y', 'sac_amplitude', 'onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_scat('fix_avgpos_x', 'fix_avgpos_y', 'sac_amplitude', 'onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_scat('fix_avgpos_x', 'fix_avgpos_y', 'sac_vmax', 'fix_avgpupilsize')"
   ]
  },
  {
   "source": [
    "## Finding Correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df[['duration', 'sac_amplitude', 'sac_endpos_x', 'sac_endpos_y', 'sac_startpos_x', 'sac_startpos_y', 'sac_vmax', 'fix_avgpos_x', 'fix_avgpos_y', 'fix_avgpupilsize', 'overlapping', 'fix_samebox', 'onset']].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))  \n",
    "\n",
    "sns.heatmap(correlation, annot=True, cmap='Greens', ax=ax)\n",
    "plt.title('Correlation between numerical parameters')"
   ]
  },
  {
   "source": [
    "It appears that `sac_amplitude` and strong correlation with `sac_vmax, fix_avgpos_x, fix_avgpos_y, fix_avgpupilsize`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot( kind='count', x='fix_type',data=df, height=8.27, aspect=20/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(kind='count', x='type',data=df, height=8.27, aspect=20/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='fix_type',kind='count',hue='type',data=df, aspect=20/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.jointplot(x='onset',y='sac_amplitude',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(y='sac_amplitude',x='onset',hue='fix_type',col='type',data=df)"
   ]
  }
 ]
}